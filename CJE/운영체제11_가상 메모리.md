이전 단원의 주소 변환, physical 메모리 접근 영역은 OS X, HW의 할 일 <br/>
BUT, 가상 메모리는 OS가 관리

**Demand Paging** <br/>
: 실제로 필요할 때, page를 메모리에 올리는 것
* 장점
    * I/O 양의 감소
    * 메모리 사용량 감소
    * 빠른 응답 시간
    * 더 많은 사용자 수용

메모리에 없는 page의 page table
* 안 쓰는 page는 backing store(디스크) <br/>
=> page table의 valid-invalid bit에 invalid라고 표기 <br/>
=> 메모리에 올라간 page는 valit bit라고 표기

CPU가 logical memory의 원하는 page를 선택<br/>
-> invalid인 경우: "page falut"(=요청한 page가 메모리에 없음)<br/>
-> MMU(주소 변환 HW)가 trap을 발생<br/>
-> 커널 모드로 들어가서 **page fault hanlder**가 실행<br/>

page fault handler
* Invalid reference? (bad addr, protection violation => abort)
    * 프로세스 외의 주소 접근이거나 권한이 없는 경우
* get empty page frame (없는 경우 뺏어온다) -> 페이지 공간 획득
* 필요한 페이지를 disk에서 메모리로 읽어옴 (I/O)
    * disk I/O가 끝날 때까지 이 프로세스는 CPU를 preempt 당함 (-> blocked)
    * disk의 read가 끝나면 page table entry에 기록 & valid bit 표기
    * ready 큐에 이 프로세스를 추가

demand paging 성능
* page fault rate: 0 <= p <= 1.0 (0에 가까움)
* p=0 : no page fault, p=1: every reference is a fault
* access time = {(1-p) x memory access} + {p x (OS & HW page fault overhead + swap page out(if need) + swap page in + OS & HW restart overhead)}

**Page replacement** <br/>
-> Free frame이 없는 경우 (메모리에 남는 페이지갸 없음)
* page fault rate가 낮아지도록 하는 것이 목표
    * 메모리에서 쫓아냈다가 다시 불러오는 일은 매우 비효율..
* 곧바로 사용되지 않을 page를 쫓아내는 것이 좋음
```
1. swap out victim page - 페이지를 메모리에서 디스크로 쫓아냄
2. change to invalid bit of victim page - 페이지 테이블에서 쫓겨난 페이지를 invalid bit로 표기
3. swap desired page in - 디스크에서 원하는 페이지를 메모리로 불러옴
4. reset page table for new page - 불러온 페이지에 대해 페이지 테이블의 내용 변경(페이지의 메모리에서의 위치(frame)과 valid bit로 표기)
```

Page replacement 알고리즘
* Optimal 알고리즘
    * 가장 먼 미래에 참조되는 page를 replace
    * 미래에 참조되는 페이지를 미리 알고 있다고 가정 -> 실제로는 불가
    * 다른 알고리즘의 성능에 대한 upper bound 제공 <br/>
    (Belady's optimal algorithm, MIN, OPT)

* FIFO (First In First Out) 알고리즘
    * 먼저 들어온 페이지를 먼저 내쫓음
    * FIFO Anomaly(Belady's Anomaly): 메모리 frame을 늘렸는데 page fault가 더 많이 발생함

* LRU (Least Recently Used) 알고리즘
    * 가장 오래 전에 사용된 페이지를 내쫓음
    * 구현: 페이지를 linked list 형태로 시간순서로 줄세우기 (LRU --- MRU)
        * 지금 참조한 페이지가 무조건 MRU의 위치로 이동
        * O(1) 복잡도 - 페이지들의 타임스탬프를 비교할 필요 X <br/>
        LRU는 무조건 list의 맨 끝

* LFU (Least Frequently Used) 알고리즘
    * 참조 횟수가 가장 적은 페이지를 지움
    * 많이 참조했던 페이지를 미래에도 참조할 확률이 높다는 생각
    * 최조 참조 횟수 page가 여러개 -> 임의 선정 or LFU 중 LRU 선정
    * 구현: 이진 트리 형태의 heap
        * 맨 위에는 LFU, 아래로 갈수록 적게 참조됨
        * 참조될 때마다 해당 페이지의 부모와 자식을 비교 <br/>
        -> 내가 자식보다 참조횟수가 많아야하고, 부모보단 참조횟수가 적어야 하는 위치 - O(log n) 복잡도

**캐슁 기법** <br/>
: 한정된 빠른 공간(캐쉬)에 요청된 데이터를 저장해 두었다가 후속 요청시 캐쉬로부터 직접 서비스하는 방식
* 페이징: 물리적 메모리(DRAM) - 캐시(빠른 곳) / 디스크 - 느린 곳
* paging system, cache system, buffer caching, Web caching, ...
* paging system: 디스크(스왑 영역), buffer caching: 디스크(파일 시스템)
* web caching: 매체간 속도차가 아닌 지리적으로 오래 걸리는 시간을 단축

캐쉬 운영의 시간 제약
* 교체 알고리즘에서 삭제할 항목을 결정하는 일에 많은 시간 X
* O(1) - 아예 비교가 없음, O(log n)정도까지만 허용, O(N) - 모두 탐색은 절대 X

**실제 paging system에서 LRU, LFU 사용 불가!!**
* 운영체제가 LRU, LFU 알고리즘을 운영하려면 메모리의 페이지가 참조되는 시점을 알아야 함
* 그런데, 메모리에 있는 페이지가 사용될 때 운영체제가 모름
    * CPU가 logical addr -> physical addr 주소변환을 할 땐 HW(MMU)가 해주고, 바로 사용자 프로세스가 사용.. OS가 CPU를 차지하지 않을 때의 일
* page fault가 발생하면 그 땐, trap 발생해서 OS가 알게 됨 (page fault handler 실행)
* 실제 페이징 시스템이 사용하는 알고리즘 - Clock 알고리즘

**Clock Algorithm** <br/>
<img src="https://user-images.githubusercontent.com/86587287/200716478-a97e53b4-58e2-4e6d-9d77-2d8c35b9c32a.png" width=300px>

* LRU의 근사 알고리즘
    * Second chance 알고리즘
    * NUR (Not Used Recently), NRU
* page 당 reference bit(access bit)가 존재
    * 주소 변환 HW가 페이지를 사용 -> reference bit(access bit)=1로 바꿈
* Reference bit를 사용해 교체할 페이지 선정 (circular list)
    * 0인 reference bit를 찾으러 포인터를 이동, 찾으면 그 페이지를 교체
    * 포인트가 이동하는 중 1인 reference bit는 0으로 바꿈
* 읽기가 발생: reference bit만 1로 바꿈
    * 쓰기도 발생: reference bit과 modified bit 둘 다 1로 바꿈
    * 쫓겨날 때 바뀐 내용을 디스크에 적어야 함

여기까지는 메모리의 페이지가 어느 프로세스의 것인지 고려 X
* -> 프로세스가 원활히 수행되기 위한 최소한의 프레임 할당량이 존재

**paging frame allocation**
* 물리적 메모리의 frame을 각 프로세스에 할당
* Equal allocation: 모든 프로세스에 똑같은 갯수 할당
* Proportional allocation: 프로세스의 크기에 비례하여 할당
* Priority allocation: 프로세스의 우선순위에 따라 다르게 할당

global replacement
* replace 시 다른 프로세스의 frame을 뺏을 수 있음
* 메모리가 많이 필요한 프로세스에게 필요한만큼 줄 수 있음 -> 독식 가능성
* 프로세스 간에 무한 경쟁

local replacement
* 프로세스별로 frame 할당
* 자신의 프로세스 중 replace할 페이지를 찾음

**Thrashing** <br/>
<img src="https://user-images.githubusercontent.com/86587287/200791811-2e08bc3f-d4f3-415f-911c-2b136cc75663.png" width=300px>

* 메모리에 프로그램 너무 적음 -> I/O하러 가는 동안 CPU는 놀아야 함
* 메모리에 프로그램 너무 많음 (**thrashing**) -> 프로그램이 원활하게 실행되기 위한 최소한의 메모리도 못 줌
    * CPU Utilization이 낮아짐
* 해결: 프로세스의 최소한의 메모리는 보장해주자 -> Working-Set model

**Working-Set Model**
* Locality of reference
    * 프로세스는 특정 시간동안 특정 페이지를 집중적으로 참조
    * 해당 페이지들을 locality set 이라고 함
* locality에 기반하여 프로세스가 일정 시간동안 원활하게 수행되기 위해 한꺼번에 메모리에 올라와 있어야하는 page들의 집합을 **Working Set**이라고 정의
* 프로세스의 working set 전체가 메모리에 올라와 있어야 수행, 아닌 경우 모든 frame을 반납 후 swap out (suspend -> 모든 working set이 보장되는 시점에 메모리에 올라감)
* Thrashing 방지 & Multiprogramming degree를 결정

Working set 결정 알고리즘
* 미래는 모르지만, 과거에 근거해서 결정
* Working set window를 통해 알아냄
    * 특정 window 크기 이내의 페이지들을 working set이라고 간주
    * ex) 이전 사용된 10개 페이지를 working set으로 결정

**PFF(Page Fault Frequency) 알고리즘** <br/>
<img src="https://user-images.githubusercontent.com/86587287/200796362-e1186b51-0b84-49ff-8c90-90e7667ce30f.png" width=300px>

* 프로세스에 메모리를 적게 할당 -> PFF 비율이 높음
* 프로세스에 메모리를 많이 할당 -> 너무 여유롭게 줌
* 상한값 & 하한값 설정하고 그 사이로 할당 frame 수를 조절

**Page Size 결정**
* 32bit 주소 체계에선 전통적으로 4K바이트...
* 메모리의 크기가 커지면서 4K바이트의 페이지로는 너무 많은 페이지가 들어옴
* Page 크기 감소
    * 많은 페이지 할당 <br/>
    -> 페이지 테이블이 커짐 & 메모리 낭비 감소(적은 메모리만 필요한데 페이지 크기 자체가 커서 낭비됐던 부분=internal fragmentation 내부조각)
    * disk transfer 효율성 감소 <br/>
    -> 근처 페이지가 필요한데, 페이지 크기가 너무 작음 -> 또 페이지를 가져와야 함
* Page의 크기가 커지는 추세    
