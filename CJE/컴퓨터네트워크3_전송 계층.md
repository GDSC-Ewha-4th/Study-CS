**Transport Layer: Application Layer 아래에 존재**
* application 계층에게 그 아래 작업은 블랙 박스
    * 우체통 구멍(소켓)에 편지 넣으면 편지 전송, 과정은 몰라도 됨
* Transport 계층의 프로토콜인 TCP, UDP 또한 그 아래 계층에 대해서는 블랙 박스
* Internet Layer의 IP (internet protocol) 위에서 동작

**계층별 데이터 전송 단위**
* application 계층의 전송 단위: Message
* transport 계층의 전송 단위: Segment
* Internet 계층의 전송 단위: Packet
* Link 계층의 전송 단위: Frame

**Multiplexing / demultiplexing** <br/>
transport 계층에서 제공하는 기본 기능 (TCP, UDP 모두)
* Multiplexing
    * Application layer -> Transport layer 로 전달 될 때, <br/>
    여러 소켓의 데이터를 모은 후 transport 계층의 header을 추가해서 **Network layer로 전달**

* Demultiplexing
    * Transport layer -> Application layer 로 전달 될 때, <br/>
    **올바른 소켓으로 전달** 하는 과정

* UDP => Connectionless
    * 소켓과 소켓 사이에 1:1 매핑 개념 X <br/>
    => 한 기기 - 다른 기기 주고 받을 때 전용 소켓 X
    * 헤더 부분에 src port, dest port 정보 저장 <br/>
    port 정보만으로 소켓 찾음 (demultiplexing)

* TCP => Connection Oriented
    * 소켓과 소켓이 1:1 관계 (다른 기기에게 연결할 소켓이 지정)
    * 소켓의 id (addressing) = **src: ip, port / dest: ip, port** <br/>
    => TCP socket identified by src ip, src port, dest ip, dest port <br/>
    4가지 정보 모두를 사용해 소켓 찾음 (demultiplexing)
    
    웹 서버의 프로세스
    * 클라이언트로부터 TCP connection => accept => 새 소켓의 id를 리턴
    * 클라이언트와 유일한 소켓이 생성, 각자를 위한 소켓

**UDP** <br/>
<img src="https://user-images.githubusercontent.com/86587287/203523902-8650ef26-5ca2-4996-93ce-16d3ad4169c1.png" width=250px>

* UDP Segment = header + data(payload)
    * data = application 계층의 message
    * header = src port, dest port, length, checksum <br/>
    (해당 전송 단위의 헤더를 알면 그 프로토콜을 알 수 있음)
        * port: 알맞은 소켓 찾아가라고 .. (=> multiplexing/demultiplexing 하려고)
* header의 크기: 32bit
    * 각 포트 번호 크기: 16 bits -> 한 기기에서 2^16개의 포트 사용 가능 (적당) <br/>
    사용 가능 포트 개수 <--trade off--> 오버 헤드 문제
    * checksum: 전송 중 data 부분에 에러가 발생했는지 확인 (parity bit)
    * length: 헤더를 포함한 segment의 크기
* no connection (sender, receiver 간에)
    * -> no delay, simple
* 작은 헤더 사이즈 -> 다양한 기능 X
* congestion control X (혼잡 컨트롤 X)

**reliable data transfer** <br/>
=> TCP에서 제공하는 중요 기능
* machine A의 TCP 소켓(sender) --> machine B의 TCP 소켓(receiver) <br/>
underlying network의 중간 라우터들을 거치면서 unreliable 가능성 있음 <br/>
unreliable: **Error 또는 Loss** 발생 => 이를 처리하면 reliable <br/>
        
**RDT** (Reliable Data Transfer protocol) <br/>
-> TCP를 이해하기 위한 가상의 프로토콜 가정

Error 처리
* error detection - feed back 
    * receiver의 피드백: ACKs(에러 X), NAKs(에러 O) <br/>
    => TCP segment의 header의 checksum을 통해 에러 체크 <br/>
    (UDP는 ACK, NAK X -> unreliable)
    * receiver: checksum으로 error detection -> ACK/NAK, sender: NAK을 받으면 재전송
* sequence number
    * 만약 ACK/NAK이 corrupted(손상된) 상태로 도착 -> sender은 receiver에게 무슨 일이 있는지 모름
    -> 무조건 retransmit -> 중복
    * sender는 header에 sequence number을 붙인 패킷 전송
    * receiver는 패킷의 seq num으로 중복 패킷인지 판단 (중복 -> 폐기)
* NAK free 
    * receiver은 무조건 ACK을 보냄 (+정상적으로 받은 마지막 패킷의 seq num)

Loss 처리
* Timer - 패킷 전송 후 피드백(ACK)이 **일정 시간** 안 오면 재전송
    * 너무 짧음 -> Loss 발생 시 빠른 재전송, 하지만 피드백이 늦게 온 지연의 경우 불필요한 재전송
    * 너무 긺 -> Loss 발생 시 느린 재전송, 지연의 경우 그만큼 피드백을 기다리는 충분한 시간(불필요한 재전송 X)
    * 패킷 loss == 피드백 loss (sender는 둘 다 피드백을 못 받았음)<br/>
    -> sender: timeout 이후 마지막으로 받은 ack 이후의 패킷을 send
    * 지연의 (premature timeout & delayed ACK)
        * 이미 timeout으로 인해 중복 패킷을 전송, 직후에 피드백
        * <img src="https://user-images.githubusercontent.com/86587287/203903242-238d13d5-0de3-43b8-8365-4d7534566698.png" width=250px>

**TCP** <br/>
<img src="https://user-images.githubusercontent.com/86587287/203907566-dcc09d59-f6f6-4bb6-88f2-a3d4514fab55.png" width=300px>

특성
* point to point: machine의 프로세스마다 각각의 소켓(TCP) (+상대 machine의 소켓 => 한 쌍의 소켓 (1:1 관계로, unique))
* **reliable**: in-order byte stream
* pipelined
* full duplex 
    * bi-directional data flow (sender이자 receiver)
* connection-oriented -> 3 way handshake
* **flow control**
    * application에서 데이터를 보내는 속도와 다르게, TCP -> network layer로 패킷을 보내는 속도는 조절 (상대방 machine)
* **congestion conrtol**
    * 중간 network 상황 고려

RTT (Round Trip Time)
* segment를 보낸 후 그에 대한 ACK이 돌아올 때까지의 시간 (sample RTT)
* network 상황마다 (=>라우터의 queuing delay에 따라) 달라짐
* EstimatedRTT = (1-a) \* EstimatedRTT + a \* sampleRTT (최신RTT가 더 많이 반영)
* timer의 timeout 설정의 근거: TimeoutInterval = EstimatedRTT + margin(여유)

각 TCP 소켓(*참고: 한 machine에는 여러 프로세스, 각 프로세스의 클라이언트마다 소켓 생성*)에는 **send buffer, rcv buffer** 존재

**sender buffer** <br/>
<img src="https://user-images.githubusercontent.com/86587287/203909766-e7a5b2ec-4d10-4ab2-841b-f733736993db.png" width=400px>

* sender 버퍼 -> receiver 버퍼
* 한 번에 여러 개의 segment를 보냄 (pipelined)
* segment 크기: 200byte -> seq num은 #0, #200, #400, ..
* timer 존재 (loss 문제 해결)

sent ACKed: send 후 ACK까지 받음 -> window가 slide (더 이상 필요 X) <br/>
sent, not yet ACKed(in-flight): send, but yet ACK X <br/>
=> 혹시 재전송할 일 생길까봐 아직 보관 <br/>
usable, not yet sent: 아직 안 보냄 <br/>
not usable <br/>

**rcv buffer** (reliable: in order delivery 구현)
* rcv buffer에 대기 시켜뒀다가 일정량이 순서대로 모이면 한번에 Application layer로 올려보냄
* receiver 쪽에서도 보낼 data가 존재 (동시에 sender) <br/>
-> segment + ACK 겸사겸사

**TCP fast retransmit** <br/>
<img src="https://user-images.githubusercontent.com/86587287/203935626-49772d7a-8051-444c-b02d-e3e0573958d4.png" width=200px> <br/>
* 3 duplicate ACK (실제로는 4번의 같은 ACK)
* timeout 보다 빠르게 감지
* rcv는 중간 segment가 유실된 채로 옴 -> 받아야 할 seq의 ACK만 보냄 <br/>
-> sender은 같은 ACK만 오니깐 유실됐음을 알아채게 됨

<img src="https://user-images.githubusercontent.com/86587287/204106053-4503d603-7e36-46d7-865b-8fec1205c630.png" width=600px>

* window size이 보낼 segment의 용량보다 크기 때문에 한 번에 전송
* rcv buffer에 순서대로 segment를 받음 -> application layer에서 read 콜로 데이터를 읽어 들임

**flow control**

* 받는 입장을 생각해서 전송
* rcv buffer의 빈 공간: **receive window**을 sender에게 알려줌 (-> TCP header)

rwnd=0에서의 데드락
* rcv buffer에 남은 공간이 없음 -> application layer에서 read 해야 남는 공간이 생김,, 그 때까지는 데이터를 보내지 않음
* 이제는 나의 rcv buffer에 공간이 생김!
    * 그런데, 내가 상대에게 보낼 데이터가 있거나 상대에게서 데이터가 와서 ACK을 보내는 경우에만 segment를 보낼 수 있음 <br/>
    => 공간이 생겨도 이를 알릴 rwnd를 보낼 방법이 없음  
* -> 내가 rwnd=0일 때, 상대가 그냥 기다리는 것이 아니라 주기적으로 아주 조그만 segment를 보냄 (=probe pkt)<br/>
--> 공간이 생기면, probe pkt에 대한 ACK에 rwnd를 함께 보냄<br/>
--> 아직 공간이 없으면 probe pkt는 버려지므로 최대한 작게 만듬

**connection management**

3 way handshake

<img src="https://user-images.githubusercontent.com/86587287/204107078-b860820d-3009-4c35-ae63-181a1b8eef25.png" width=300px>

* 1st segment(SYN msg)
    * SYNbit=1 (이 segment가 SYN임을 표시, 평소에는 0), Seq=x(init seq num)
* 2nd segment(SYNACK)
    * SYNbit=1, Seq=y(init seq num), acking SYN -> ACKbit=1(ACK임을 표시), ACKnum=x+1
* 3rd segment(ACK for SYNACK)
    * ACKbit=1, ACKnum=y+1
    * data를 넣을 수 있음

close connection

<img src="https://user-images.githubusercontent.com/86587287/204107172-45736967-3ad1-4821-8a8f-d276f4eade08.png" width=450px>

* 클라이언트가 소켓을 닫겠다고 판단: clientSocket.close() <br/>
 -> FINbit=1, Seq=x
    * 더 이상 data send X, 하지만 아직 receive data O
* ACKbit=1, ACKnum=x+1
    * FINbit에 대한 ACK
    * 아직 send data는 가능
* 서버도 close 하겠다고 판단 <br/>
-> FINbit=1, Seq=y
    * 더 이상 data send X
* ACKbit=1, Acknum=y+1
    * FINbit에 대한 ACK
* 서버가 클라이언트의 ACK을 못 받고 하염없이.. FINbit를 날리는 상황을 대비해서, 2 x max segment lifetime만큼 종료하지 않고 대기

**congestion control** <br/>
네트워크가 처리할 수 있는 양보다 더 많은 데이터가 네트워크에 존재  

문제
* lost packets (buffer overflow at routers)
* long delays (queuing in router buffers)

TCP는 재전송이 가능 -> congestion -> loss or premature timeout 발생시 재전송 -> 실제 데이터 양보다 보낸 양이 많아짐

많이 보내서 네트워크가 congestion -> BUT, congestion 때문에 더 많이 보내게 됨

라우터 중간에 drop -> 네트워크 자원 낭비

<img src="https://user-images.githubusercontent.com/86587287/204202496-9319965c-3e9d-41fe-90fd-d91078410299.png" width=200px>

* 많이 보냄 -> 네트워크 congestion -> loss & delay
* 적게 보냄 -> 네트워크 상황이 괜찮을 때는 많이 보낼수록 많이 도착

sender buffer의 window size: receive window와 congestion window 중 작은 값으로 설정
* -> receiver와 네트워크에서 둘 다 overflow 되지 않기 위해 

**AIMD(additive increase multiplicative decrease) - cwnd 결정** <br/>
<img src="https://user-images.githubusercontent.com/86587287/204203415-77f82fe5-f4a4-416b-ab4b-f1f137c861a4.png" width=400px>
* additive increase: 1 MSS씩 증가(RTT마다)
* multiplicative decrease: 1/2로 감소

**TCP Slow Start** <br/>
<img src="https://user-images.githubusercontent.com/86587287/204210701-ee116d8e-e29a-47be-8c15-145363bc85e6.png" width=200px>

* 첫 cwnd: 1 MSS
* RTT마다 2배씩 늘림
* ssthresh (slow start threshold - 임계값)에서부터는 linear increase(1 MSS씩 증가) (congestion avoidance)
    * loss발생한 순간 -> ssthresh = cwnd/2

**loss의 근거 -> timeout & 3 duplicate ACK**
* loss를 통해서 네트워크 상황을 추측
* duplicate ACK은 네트워크 상황은 괜찮은데 우연하게 어떤 segment만 유실
* timeout이 더 혼잡한 네트워크를 의미
    * 많은 segment를 보내도 다 loss 되어서 중복 ACK도 X

<img src="https://user-images.githubusercontent.com/86587287/204210828-19db9208-32f0-44d6-8130-7c2033937577.png" width=400px>

**TCP RENO**
* loss(timeout) 
    * -> enter SS (init 1 MSS)
    * ssthresh = cwnd/2
* loss(3 duplicate ACK)
    * ssthresh = cwnd/2
    * cwnd = cwnd/2 
    * grows linearly

**TCP TAHOE**
* loss(timeout, 3 duplicate ACK) -> enter SS (init 1 MSS) & ssthresh=cwnd/2

**TCP Throughput** -> 네트워크 상황에 따라 달라짐 <br/>
평균: (3/4) * (W/RTT) bytes/sec <br/>
한 번 전송할 때 (RTT) W만큼 전송한다는 의미

**TCP Fairness** <br/>
=> 각 기기가 R/K의 rate로 전송하면 fair <br/>
R: 라우터의 capacity, K: Tcp sessions(TCP segment를 보낼 connection)
* 그런데, 이건 connection 입장에서 fair, 한 host(기기)에서 여러개의 connection을 가질 수 있기 때문에.. 기기 입장에서의 fair X