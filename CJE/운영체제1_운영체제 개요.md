## __🦈 운영체제란?__
* 컴퓨터 HW 바로 위에 설치
* 사용자 및 다른 모든 SW와 HW를 연결하는 SW 계층

<img src="https://user-images.githubusercontent.com/86587287/192683367-b64b4dbe-3b51-42b9-96ee-43e92bc45d0a.png" width=400px>

## __🦈 운영체제의 목적__
1. 컴퓨터 시스템을 편리하게 사용
* 동시 사용자/프로그램들이 독자적 컴퓨터에서 수행되는 것 같은 환상을 제공 
    * -> 실시간 프로그램들이 매우 짧은 시간씩 CPU에 번갈아 가며 할당
* HW를 직접 다루는 복잡한 부분을 대신 해줌

2. __컴퓨터 시스템의 자원을 효율적으로 관리__
* CPU(프로세서), 메모리, I/O 장치 등의 효율적 관리
    * 주어진 자원으로 최대한의 성능 -> 효율성
    * 특정 사용자/프로그램의 지나친 불이익 X -> 형평성

## __🦈 컴퓨터 시스템의 구조__

<img src="https://user-images.githubusercontent.com/86587287/192684108-1eff6bb7-2820-4665-a618-92aee884d2ea.png" width=400px>

* CPU가 기계어 실행
* I/O 장치 -> input & output 데이터
    * 하드디스크는 컴퓨터 외부로 분류 -> in & out 모두 가능

## __🦈 컴퓨터 시스템의 구조__

<img src="https://user-images.githubusercontent.com/86587287/192685734-c8a4f0d9-dccd-4267-8157-bcc75192521e.png" width=450px>

🐬 운영 체제의 가장 큰 관심사
1. CPU 스케줄링
2. 메모리 관리
3. 디스크 스케줄링
4. 캐슁, 인터럽트

🐬 부팅 -> 운영체제가 메모리에 올라가서 실행
* 컴퓨터가 꺼지기 전까지 계속 메모리에 올라가 있음
    * -> *운영체제의 핵심적인 부분 : 커널*
    * 나머지

🐬 메모리: CPU의 작업 공간
* 메모리에 올라간 프로그램 & 운영체제의 기계어를 CPU가 처리

🐬 IO 디바이스에는 전담 CPU들이 있음

🐬 CPU 스케줄링 -> 어떤 프로그램에게 얼마동안 CPU 사용권을 줄까?
* CPU는 HW, 직접 선택 못함
* CPU를 어느 프로그램으로 넘길지 선택하는 것도 운영체제가 처리
* 일정 시간이 지나면 뺏어서 다른 프로그램에게 CPU를 넘기는 것도 운영체제 - 무한정 CPU 독점을 막음
* **그런데,,?** 이미 다른 프로그램에게 CPU를 넘긴 상태엔데,, OS가 어떻게 ?? -> **다른 HW 장치와 협조..**

🐬 디스크 스케줄링 -> 디스크는 CPU에 비해서는 대단히 느린 장치...
* 마냥 순서대로 처리하는 것보다 효율적인 방법으로 처리
* -> 엘리베이터 스케줄링과 비슷

🐬 캐슁
* 중간에 캐시를 둠
* 디스크에 있는 파일을 읽어달라는 요청이 올 때마다 디스크에 접근 X
* 같은 요청에 대해서 메모리 어딘가에 잠시 저장해둔 캐시를 읽어줌

🐬 인터럽트 (가로채기?)
* 디스크에서 파일을 읽어줘~ 시키고 기다리는 동안 CPU가 놀고 있는 것은 매우 낭비
    * 속도 차이가 매우 큼..
* -> 프로그램 A는 I/O에 접근해서 파일을 읽어오느라 오래 기다림 -> 그동안 프로그램 B(금방 할 수 있음)를 하고 있자
* CPU는 놀고 있지 마
* 프로그램 B를 실행중이던 CPU에게 프로그램 A의 I/O 처리가 끝났습니다. 라고 인터럽트를 통해 알림
* CPU는 프로그램B의 기계어를 실행하다가 (기계어 하나 하나 중간에 인터럽트 체크) 인터럽트 --> CPU 제어권이 운영체제로 넘어감 -> 원래 하던 프로그램 A로 돌아감

## __🦈 프로세스의 상태__

<img src="https://user-images.githubusercontent.com/86587287/192686655-124830e9-db93-4538-beaf-6a5097499d24.png" width=450px>

* CPU를 쓰고자하는 프로그램들을 CPU큐에 넣어서 줄 세움
* CPU 조금 쓰고 큐의 맨 뒤에 넣고,,를 반복 -> 동시에 처리되고 있는 기분..
* 디스크 입출력이 필요한 프로세스는 디스크 입출력 큐에 넣음

🐬 Interactive Application - I/O에 접근할 일 많음

🐬 Scientific Application - CPU에만 오래 접근.. (I/O 쓰임 적음)

## __🦈 CPU 스케줄링 - FCFS__

<img src="https://user-images.githubusercontent.com/86587287/193591914-83a733d7-88fa-4ad0-91d7-9e181f65e0e4.png" width=450px>

* 프로세스들의 도착 순서는 간발의 차이라고 가정
* 프로세스들은 CPU를 쓰기 위해 CPU 프로세스 큐에서 대기
* IO 장치를 쓰기 위해 IO 프로세스 큐에서 대기 후 사용
    * 사용 끝나면 처리가 끝나면 CPU에게 인터럽트를 통해 알림
    * CPU는 하던 기계어만 처리 후 운영체제에게 제어권이 넘어감
    * 운영체제가 IO 수행을 끝낸 기존 프로세스에게 제어권을 돌려줌

FCFS (First - Come First - Served)
* 먼저 도착한 P1이 필요한 만큼 (24초) 쓰고 끝 (또는 IO 사용하러 가기 등 ...)
* 순서대로 수행
* -> 공평하지만, 효율적이진 않음

Waiting time 
* P1 = 0, P2 = 24, P3 = 27
* 평균: (0 + 24 + 27)/3 = 17 -> 효율 X

만약, CPU를 조금만 쓰는 P2, P3가 먼저 도착??
* Waiting time: P1 = 6, P2 = 0, P3 = 3
* 평균: (6 + 0 + 3)/3 = 3

## __🦈 CPU 스케줄링 - SJF__

<img src="https://user-images.githubusercontent.com/86587287/193593754-933f1e6f-fcd7-4320-8cb0-3132becf8f05.png" width=450px>

SJF (Shortest - Job - First)
* CPU 프로세스 큐 중에서 **CPU 사용시간이 가장 짧은 프로세스 가장 먼저 스케줄**
* -> Mininum Average Waiting Time을 보장
* -> 가장 효율적인 방법이지만, 가장 형평성이 없음

문제
* 기아 현상
* 기다리는 와중에 나보다 짧은 이용시간의 프로세스들이 계속 추가?
    * 오래 걸리는 프로세스는 평생 못 하게 될 수도. . .

지금까지의 (FCFS, SJF) 스케줄링 방법은
* 사용중인 프로세스를 뺏지 않음

## __🦈 CPU 스케줄링 - RR__

<img src="https://user-images.githubusercontent.com/86587287/193594654-97a93af7-c3f8-4a6a-8f69-d621e426f179.png" width=450px>

RR (Round - Robin)
* 각 프로세스는 동일한 CPU 할당 시간을 가짐
* 할당 시간이 끝나면 **인터럽트 발생** -> CPU 뺏김
    * HW의 도움
* 현대 CPU 스케줄링으로 많이 사용됨

할당 시간 > 필요 시간
* 원하는 만큼 CPU 사용 후 할 일 하러 나감 (IO)

할당 시간 < 필요 시간
* 할당 시간만큼 쓴 후 뺏김
* CPU 프로세스 대기 큐의 맨 뒤로 다시 줄 서기

공정 & 효율
* 어떤 프로세스도 (n-1)*할당 시간 이상을 기다리진 않음
    * 당연함
    * 앞 프로세스가 할당 시간 이하로 쓰면 더 조금 기다려도 됨
* 대기 시간이 내가 CPU를 많이 사용하고 싶은 만큼 비례함
    * 내가 할당 시간 이상으로 많~이 쓰고 싶으면
    * 쓰고 기다리고 쓰고 기다리고를 반복하면 됨


## __🦈 메모리 관리__

<img src="https://user-images.githubusercontent.com/86587287/193596000-ce8833f3-ca98-4be3-bfe5-f41ce8a3b7f2.png" width=450px>

🐬 메모리는 휘발성 
* 컴퓨터의 전원이 나가면 사라짐

🐬 디스크(파일 시스템)의 실행 파일 A, B를 실행시키면 메모리에 프로세스로 올라가게 됨
* 바로 올라가는 건 아니고 **가상 메모리**를 거침 - 주소 공간을 가짐
* 내가 프로세스가 되어 메모리를 어떻게 형성해야 할까?
* 가상 메모리 중 **당장 필요한 부분만 메모리에 올림**
* 컴퓨터의 전원이 나가도 유지

🐬 **당장 필요하지 않은 프로세스 부분은 디스크(스왑 영역)으로 이동**
* 당장 필요한 부분은 물리적 메모리에 올라감
* 당장 필요 X - 디스크 스왑 영역로 쫓겨남
* -> **메모리의 연장 공간**
* 전원이 나가도 살아는 있음 (비휘발성)
    * 하지만 의미는 없음
    * 프로세스는 전원이 켜져있을 때 실행되는.. 전원이 켜져있어야 의미 O
    * 그러므로, 프로세스의 일부를 저장해둔 디스크 스왑영역도 전원이 꺼지면 의미 X

🐬 어떤 페이지(프로세스를 쪼갠 부분)를 디스크(스왑 영역)으로 쫓아낼 것이냐?

## __🦈 메모리 관리 - LRU vs LFU__

<img src="https://user-images.githubusercontent.com/86587287/193599775-34f07340-3b43-4cb6-a147-f042e9c8af2f.png" width=450px>

* 필요한 1 페이지를 처음 사용할 때
    * 디스크에 접근해서 1 페이지를 받아서 메모리에 올림
    * 디스크는 IO 장치로 접근하기까지 시간 오래 걸림
    * 다음부터는 디스크까지 안 가도 사용 가능
* 2 페이지를 처음 사용할 때, 3 페이지, 4 페이지 ...
* -> 1234 페이지가 메모리에 올라옴

5 페이지가 필요하면?? -> 어떤 페이지를 디스크(스왑 영역)으로 쫓아낼까??
* 미래에 가장 많이 사용될 페이지를 메모리에 남기는 게 효율적
* -> 그런데??? 미래를 모름...
* 미래를 예측하는 방법???? -> 과거를 보기

🐬 LRU - 가장 오래 전에 사용된 페이지를 삭제
* 1 페이지가 사용된 지 가장 오래됨
* -> 1 페이지를 메모리에서 쫓아냄
* 최근에 사용된 페이지가 미래에도 쓰이겠다.. -> 남기자 예측

🐬 LFU - 사용된(참조) 횟수가 가증 적은 페이지를 삭제
* 사용 횟수가 가장 적은 페이지를 삭제
* -> 4 페이지를 삭제
* 많이 쓰인 페이지는 또 사용될 확률이 높음 예측
* 인기 있는 데이터만 편향되게 계속 사용된다.. 는 예측

## __🦈 디스크 스케줄링__

<img src="https://user-images.githubusercontent.com/86587287/193601043-2bfa596d-82f0-451f-b213-a2fa768815c5.png" width=450px>

* 디스크(파일시스템)의 파일을 읽고 쓰는 요청이 디스크 큐에 쌓임
* 디스크 헤드가 이동하면서 파일을 읽고 씀
* 동심원 트랙 1번 ~ 100번
    * 1번 트랙의 데이터를 읽어라~
    * 100번 트랙의 데이터를 읽기 위해서는 1->100으로 이동
    * **디스크 사용 시간의 가장 큰 비율 -> 디스크 헤드의 이동 시간**
    * -> 큐의 순서대로 이동하는 방법은 비효율적
    * 2 --> 99 --> 3 --> 100 --> 1

🐬 **디스크의 이동 거리를 줄이는 방법으로 스케줄링**

<img src="https://user-images.githubusercontent.com/86587287/193603430-44f540e7-f502-4bd0-b31f-8343cc832e34.png" width=450px>

🐬 디스크 접근 시간의 구성
* 탐색 시간 (Seek Time)
    * 헤드를 해당 트랙(실린더)로 움직이는데 걸리는 시간
* 회전 지연 (Rotational Latency)
    * 해당 트랙에서 헤드가 원하는 섹터로 도달하는데 걸리는 시간
* 전송 시간 (Transfer Time)
    * 데이터의 전송 시간

🐬 탐색 시간이 가장 큰 비중을 차지
* -> **디스크 스케줄링의 목표: 탐색 시간 (Seek Time)을 줄이자**

## __🦈 디스크 스케줄링 - FCFS__

<img src="https://user-images.githubusercontent.com/86587287/193604388-f1064912-1d6c-4471-b117-f1eac34c7cdf.png" width=450px>

FCFS (First - Come First - Served)
* 디스크 프로세스 큐에 들어온 순서대로 처리
* 비효율..

## __🦈 디스크 스케줄링 - SSTF__

<img src="https://user-images.githubusercontent.com/86587287/193604704-76b50238-99a7-46fd-9e6c-f832c27c6014.png" width=450px>

SSTF (Shortest Seek Time First)
* 현재 위치를 기준으로 가장 가까운 순서로 처리
* 이동 거리는 좀 짧아짐...

문제
* 기아 문제 (Starvation)
* CPU 스케줄링 방법 중 SJF (Shortest - Job - First)과 같은 문제..
    * 당장 효율적인 (짧게 끝날 수 있는 프로세스) 것만을 우선하는 방법들
* 효율성은 좋지만, 형평성 X

## __🦈 디스크 스케줄링 - SCAN__

<img src="https://user-images.githubusercontent.com/86587287/193605617-f36dab45-1d61-49b1-b607-7e8aa8972aa8.png" width=450px>

SCAN
* 큐에 들어와있는 요청은 전혀 상관 X
* 한쪽 끝 -> 다른쪽 끝으로 왕복하면서 이동
* **이동하면서 가는 길목에 있는 요청을 처리해나감**
* 현대 디스크 스케줄링 방법으로 잘 쓰임
* = 엘리베이터 스케줄링

## __🦈 저장장치 계층 구조와 캐싱__

<img src="https://user-images.githubusercontent.com/86587287/193614233-f63f7058-72d2-4a0e-ad26-210625c3b867.png" width=450px>

🐬 Primary
* CPU는 Register 보다 위에 위치
* Main 메모리 (DRAM)
* Cache Memory: Register - Main Memory 사이의 속도차이를 완충
* 빠르고 비쌈 -> 적응 용량만 사용 & 휘발성
* -> 컴퓨터의 내부

🐬 Secondary
* 디스크
* 느리고 쌈 -> 많은 용량 사용 & 비휘발성
* -> 컴퓨터의 외부 (IO 자치)

🐬 속도 차이 완충
* 속도 차이를 완충하기 위해 계층 구조 사용
* -> 캐슁

🐬 캐슁
* 동일한 데이터라면 빠른 장치에 저장해 둠
* 맨 밑까지 내려가서 가져올 필요 없음
* BUT, 한정적인 용량
* 쫓아내는 기준? -> LRU? LFU?

## __🦈 플래시 메모리__

<img src="https://user-images.githubusercontent.com/86587287/193614793-93008a11-86ed-4f7a-a01e-f5a5a209883d.png" width=450px>

🐬 반도체 장치
* NAND 형 (스토리지) -> 우리가 사용하는 것들은 대부분 이거
* vs 하드디스크는 HW 장치 - 마그네틱 장치
* 이제는 하드디스크를 대체

🐬 특징
* 비휘발성
* 전력 소모가 적음 (하드디스크는 트랙을 돌리는데 많은 전력 사용)
* 물리적으로 강함 - Shock resistance
* 작은 사이즈
* 가벼운 무게
* 쓰기 횟수 제약 (ex 10,000번 쓰면 이제 더이상 사용 X)
* --> 모바일 장치에 사용 & 하드디스크 대용

🐬 단점?
* 하드디스크의 경우 오랜 시간이 지나도 유지 가능
* 셀 안에 들어간 전하의 양으로 0 or 1 구분
* 시간이 지나면 전하가 빠져나감
* -> 오랜 시간 유지 X

## __🦈 운영체제의 종류__
* 서버용
    * Linux, ...
    * 데이터 센터
* PC용
    * MacOS, Windows, Linux, ...
* 스마트디바이스용 
    * iOS, Android, Linux, ...

Linux는 공개 소프트웨어 (Open Source)
* 소스 코드가 공개 
    * -> 각 환경에 맞게 수정 가능
    * Windows OS를 쓰면서도 Linux 소스를 변형해서 같이 사용 가능
